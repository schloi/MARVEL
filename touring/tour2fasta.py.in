#!@PYTHON3@

from __future__ import print_function

import sys
import string
import argparse
import os
import math
import array

from constants import *

from marvel import DB
from marvel import LAS
import marvel.config

try:
    import networkx as nx
except:
    print("The networkx library doesn't seem to be installed on your system.")
    sys.exit(1)

###
#

def e_source(e):
    return e[0]

def e_target(e):
    return e[1]

#
###

def trace_to_posmap(trace, alen):
    a = 0
    ac = 0

    # posmap = [None] * alen
    posmap = array.array("l", [-1] * alen)

    for p in trace:
        if p < 0:
            p = -p - 1

            while a < p:
                posmap[a] = ac
                a += 1
                ac += 1

            ac += 1
        else:
            p -= 1

            while ac < p:
                posmap[a] = ac
                a += 1
                ac += 1

            posmap[a] = -1
            a += 1

    p = alen
    while a < p:
        posmap[a] = ac
        a += 1
        ac += 1

    return posmap

def reverse(edir):
    if edir == 'l':
        return 'r'
    else:
        return 'l'

g_revcomp = str.maketrans("ACGTacgt", "TGCAtgca")
def revcomp(seq):
    seq = str(seq).translate(g_revcomp)
    return seq[::-1]

def wrapSeq(strSeq):
    arrLines = []

    for i in range(0, len(strSeq), 50):
        arrLines.append( strSeq[i : i+50] )

    return "\n".join( arrLines )

def convert_interval(trace, b, e):
    b_c = -1
    while b_c == -1 and b < e:
        b_c = trace[ b ]
        b += 1

    # in case the whole interval has been discarded during correction
    # could happen with very short overhangs at contig ends

    if b == e:
        return (len(trace) - 1, len(trace) - 1)

    e -= 1
    e_c = -1
    while e_c == -1 and e > b:
        e_c = trace[ e ]
        e -= 1
    e_c += 1

    assert(b_c != -1)
    assert(e_c != -1)

    return (b_c, e_c)

def write_path_corrected(fileOut, seqname_prefix,
                         db, track_source, track_trim,
                         dbc, srid2crid, ttrace,
                         vread, eflags, elen, eend, path, pathid, e1, e2):
    if len(path) == 0:
        return 0

    edir = eend[ path[0] ]

    if edir == 'l':
        bComp = True
    else:
        bComp = False

    v = e_source(path[0])

    rid = vread[v]
    (trim_b, trim_e) = track_trim.get(rid)

    # convert trim interval
    ridc = srid2crid[rid]
    trace = trace_to_posmap(ttrace.get(ridc), db.length(rid))
    (trim_b_c, trim_e_c) = convert_interval(trace, trim_b, trim_e)

    seq = dbc.sequence(ridc)[trim_b_c : trim_e_c]

    if bComp:
        seq = revcomp(seq)

        pathRid = [ (ridc, trim_e_c, trim_b_c) ]
    else:
        pathRid = [ (ridc, trim_b_c, trim_e_c) ]

    if track_source != None:
        pathSource = [ track_source.get(rid)[0] ]
    pathSeq = seq

    for e in path:
        assert(e_source(e) == v)

        flags = eflags[e]
        v = e_target(e)
        rid = vread[v]

        (trim_b, trim_e) = track_trim.get(rid)

        ridc = srid2crid[rid]
        trace = trace_to_posmap(ttrace.get(ridc), db.length(rid))

        seq = dbc.sequence(ridc)

        if flags & LAS.OVL_COMP:
            bComp = not bComp

        if bComp:
            ovh_end = trim_b + elen[e]

            (trim_b_c, ovh_end_c) = convert_interval(trace, trim_b, ovh_end)

            pathRid.append( (ridc, ovh_end_c, trim_b_c) )

            pathSeq += revcomp(seq[trim_b_c : ovh_end_c])
        else:
            ovh_beg = trim_e - elen[e]

            (ovh_beg_c, trim_e_c) = convert_interval(trace, ovh_beg, trim_e)

            pathRid.append( (ridc, ovh_beg_c, trim_e_c) )

            pathSeq += seq[ovh_beg_c : trim_e_c]

        if track_source != None:
            pathSource.append( track_source.get(rid)[0] )
        else:
            pathSource = []

    fileOut.write(">{}_{} path={} ends={},{} length={} reads={} sreads={}\n{}\n".format(seqname_prefix, pathid, pathid,
                    e1, e2,
                    len(pathSeq),
                    ",".join( [ "{},{},{}".format(*x) for x in pathRid ] ),
                    ",".join( [ str(x) for x in pathSource ] ),
                    wrapSeq(pathSeq)))

    return len(pathSeq)

def write_path(fileOut, seqname_prefix, db, track_source, track_trim, vread, eflags, elen, eend, path, pathid, e1, e2):
    if len(path) == 0:
        return 0

    edir = eend[ path[0] ]

    if edir == 'l':
        bComp = True
    else:
        bComp = False

    v = e_source(path[0])

    rid = vread[v]
    (trim_b, trim_e) = track_trim.get(rid)

    seq = db.sequence(rid)[trim_b : trim_e]
    if bComp:
        seq = revcomp(seq)

        pathRid = [ (rid, trim_e, trim_b) ]
    else:
        pathRid = [ (rid, trim_b, trim_e) ]

    if track_source != None:
        pathSource = [ track_source.get(rid)[0] ]
    pathSeq = seq

    for e in path:
        assert(e_source(e) == v)

        flags = eflags[e]
        v = e_target(e)
        rid = vread[v]

        (trim_b, trim_e) = track_trim.get(rid)

        seq = db.sequence(rid)

        if flags & LAS.OVL_COMP:
            bComp = not bComp

        if bComp:
            ovh_end = trim_b + elen[e]

            pathRid.append( (rid, ovh_end, trim_b) )

            pathSeq += revcomp(seq[trim_b : ovh_end])
        else:
            ovh_beg = trim_e - elen[e]

            pathRid.append( (rid, ovh_beg, trim_e) )

            pathSeq += seq[ovh_beg : trim_e]

        if track_source != None:
            pathSource.append( track_source.get(rid)[0] )
        else:
            pathSource = []

    fileOut.write(">{}_{} path={} ends={},{} length={} reads={} sreads={}\n{}\n".format(seqname_prefix, pathid, pathid,
                    e1, e2,
                    len(pathSeq),
                    ",".join( [ "{},{},{}".format(*x) for x in pathRid ] ),
                    ",".join( [ str(x) for x in pathSource ] ),
                    wrapSeq(pathSeq)))

    return len(pathSeq)

def process_graph(g, db, dbc, fileSeq, arrPaths, track_trim_name, seqname_prefix):
    vread_prop = { n : g.node[n]["read"] for n in g.nodes() }

    eflags_prop = { e : g.edges[e[0], e[1]]["flags"] for e in g.edges() }
    elen_prop = { e : g.edges[e[0], e[1]]["length"] for e in g.edges() }
    eend_prop = { e : g.edges[e[0], e[1]]["end"] for e in g.edges() }

    track_source = db.track("source")
    track_trim = db.track(track_trim_name)

    if dbc:
        tsrc = dbc.track("source")
        ttrace = dbc.track("postrace")

        print("mapping read ids")
        srid2crid = {}

        for i in range( dbc.reads() ):
            (srid, dummy, dummy) = tsrc.get(i)
            srid2crid[srid] = i
    else:
        srid2crid = None
        ttrace = None

    total = 0
    for (pid, e1, e2, path) in arrPaths:

        if dbc:
            plen = write_path_corrected(fileSeq, seqname_prefix, db, track_source, track_trim, dbc, srid2crid, ttrace, vread_prop, eflags_prop, elen_prop, eend_prop, path, pid, e1, e2)
        else:
            plen = write_path(fileSeq, seqname_prefix, db, track_source, track_trim, vread_prop, eflags_prop, elen_prop, eend_prop, path, pid, e1, e2)

        total += plen
        print("wrote path {} length {} total {}".format(pid, plen, total))

def main():
    parser = argparse.ArgumentParser(description = "")

    parser.add_argument("database", help = "database used to build and tour the graph")
    parser.add_argument("graph_path_pairs", metavar = "graph path", nargs="+", help = "toured graph and path pairs")
    parser.add_argument("-c", "--corrected", metavar = "corrected.db", default = None, help = "database containing the corrected reads")
    parser.add_argument("-s", "--split", default = False, action="store_true")
    parser.add_argument("-p", "--prefix", metavar = "file.prefix", default = "path", help = "fasta sequence name prefix")
    parser.add_argument("-t", "--trimTrack",
                        dest = "trimTrack", type = str,
                        default = "trim", metavar = "track",
                        help = "trim track used to build the overlap graph")

    args = parser.parse_args()

    if len(args.graph_path_pairs) % 2:
        parser.error("graph_path_pairs should be pairs of .graphml and .path files")

    print("opening db {}".format(args.database))

    db = DB.DB(args.database)
    track_trim_name = args.trimTrack
    seqname_prefix = args.prefix

    if args.corrected:
        print("opening corrected db {}".format(args.corrected))
        dbc = DB.DB(args.corrected)
    else:
        dbc = None

    for fname in args.graph_path_pairs:
        if not os.path.exists(fname):
            print("file {} not found".format(fname))
            continue

    for i in range(0, len(args.graph_path_pairs), 2):
        fgraph = args.graph_path_pairs[i]
        fpaths = args.graph_path_pairs[i + 1]

        basename = fgraph.rpartition(".")[0]
        of = basename + ".fasta"

        print("loading graph {}".format(fgraph))

        try:
            g = nx.read_graphml(fgraph)
        except Exception as e:
            print("error: failed to load graph: " + str(e))
            sys.exit(1)

        fileSeq = open(of, "w")

        paths = []

        for line in open(fpaths):
            line = line.strip()

            if len(line) == 0:
                continue

            items = line.split(" ")
            pid = int(items[1])
            e1 = int(items[2])
            e2 = int(items[3])

            path = []
            for edge in items[4:]:
                (n1, n2) = edge.split("-")
                path.append( (n1, n2) )

            paths.append( (pid, e1, e2, path) )

        ### split aggressively at junctions
        #

        if args.split:
            ends = {}
            max_pid = 0

            for (pid, e1, e2, path) in paths:
                if len(path) == 0 or e1 != -1 and e1 == e2:
                    continue

                ends[ path[0][0] ] = pid
                ends[ path[-1][1] ] = pid

                if pid > max_pid:
                    max_pid = pid

            next_pid = pow( 10, int( math.ceil( math.log10(max_pid + 1) ) ) )
            paths_split = []

            for (pid, e1, e2, path) in paths:

                beg = 0
                for j in range( 1, len(path) - 1 ):
                    (vf, vt) = path[j]

                    if vf in ends:
                        paths_split.append( (next_pid, e1, e2, path[beg:j]) )
                        beg = j

                        next_pid += 1

                if beg == 0:
                    paths_split.append( (pid, e1, e2, path) )
                else:
                    paths_split.append( (next_pid, e1, e2, path[beg:]) )
                    next_pid += 1

            del ends

            print("split {} into {} paths".format(len(paths), len(paths_split)))

            v2p = {}
            p2l = {}
            for (pid, e1, e2, path) in paths_split:
                p2l[ pid ] = len(path)

                for e in path:
                    if e[0] not in v2p:
                        v2p[ e[0] ] = []

                    v2p[ e[0] ].append( pid )

                    if e[1] not in v2p:
                        v2p[ e[1] ] = []

                    v2p[ e[1] ].append( pid )

            for key in v2p:
                v2p[key].sort( key = lambda x: p2l[x], reverse = True )

            for i in range( len(paths_split) ):
                (pid, e1, e2, path) = paths_split[i]
                e1 = -1
                e2 = -1

                if len(path) > 1:
                    for p in v2p[ path[0][0] ]:
                        if p != pid:
                            e1 = p
                            break

                    for p in v2p[ path[-1][1] ]:
                        if p != pid:
                            e2 = p
                            break

                paths_split[i] = (pid, e1, e2, path)

            paths = paths_split

        #
        ###

        process_graph(g, db, dbc, fileSeq, paths, track_trim_name, seqname_prefix)

        fileSeq.close()

if __name__ == "__main__":
    if not marvel.config.has_recent_python():
        sys.exit(1)

    main()
